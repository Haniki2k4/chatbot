# Chatbot Bá»‡nh Viá»‡n Äá»©c Giang

> Chatbot RAG (Retrieval-Augmented Generation) sá»­ dá»¥ng BERT Embedding + LLM Local (Qwen2.5 / Llama)

## ğŸ“‹ Má»¥c lá»¥c

- [TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng)
- [YÃªu cáº§u há»‡ thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u trÃºc dá»± Ã¡n](#-cáº¥u-trÃºc-dá»±-Ã¡n)
- [API Documentation](#-api-documentation)
- [Cáº¥u hÃ¬nh](#-cáº¥u-hÃ¬nh-configsettingspy)
- [Troubleshooting](#ï¸-troubleshooting)

## âœ¨ TÃ­nh nÄƒng

- âœ… Semantic search vá»›i BERT embeddings
- âœ… LLM local (Qwen2.5 1.5B hoáº·c Llama 3.2 1B)
- âœ… Ranking vá»›i xÃ¡c suáº¥t (Softmax normalization)
- âœ… Web interface vá»›i Flask
- âœ… REST API cho chatbot
- âœ… Cache optimization (pickle)
- âœ… Response time tracking
- âœ… Vietnamese language support

## ğŸ”§ YÃªu cáº§u há»‡ thá»‘ng

- **Python**: 3.8+
- **RAM**: >= 4GB
- **CPU**: 2+ cores (khuyáº¿n nghá»‹)
- **Disk**: >= 2GB (cho models)

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. Clone / Setup repository
```bash
cd chatbot
```

### 2. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 3. Chuáº©n bá»‹ dá»¯ liá»‡u

**TÃ¹y chá»n A: Crawl dá»¯ liá»‡u tá»± Ä‘á»™ng**
```bash
python scripts/download_model.py  # Download LLM models
```

**TÃ¹y chá»n B: Sá»­ dá»¥ng dá»¯ liá»‡u cÃ³ sáºµn**
- Äáº·t cÃ¡c file `.txt` vÃ o thÆ° má»¥c `data/raw/duc_giang_txt/`

### 4. Download LLM Models (tÃ¹y chá»n)
```bash
python scripts/download_model.py
```

Hoáº·c download thá»§ cÃ´ng:
- [Qwen2.5 1.5B](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF)
- [Llama 3.2 1B](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct-GGUF)

Äáº·t vÃ o: `data/models/`

## ğŸš€ Sá»­ dá»¥ng

### Mode Web Interface (Recommended)
```bash
python web/app.py
```
Truy cáº­p: `http://localhost:5000`

### Mode CLI
```bash
python scripts/run_cli.py
```

### Python API
```python
from src.chatbot_engine import DucGiangChatbot

# Khá»Ÿi táº¡o chatbot
bot = DucGiangChatbot()

# Láº¥y cÃ¢u tráº£ lá»i
response = bot.get_response("Bá»‡nh viá»‡n má»Ÿ cá»­a lÃºc máº¥y giá»?")
print(response)

# Vá»›i chi tiáº¿t
response, scores, inference_time = bot.get_response(
    "Bá»‡nh viá»‡n má»Ÿ cá»­a lÃºc máº¥y giá»?",
    return_scores=True
)
print(f"Response: {response}")
print(f"Inference time: {inference_time:.2f}s")
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
chatbot/
â”œâ”€â”€ README.md                      # TÃ i liá»‡u nÃ y
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ config/                        # Cáº¥u hÃ¬nh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py               # Cáº¥u hÃ¬nh toÃ n cá»¥c
â”‚
â”œâ”€â”€ src/                           # Source code chÃ­nh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chatbot_engine.py          # Engine chÃ­nh
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”‚
â”œâ”€â”€ data/                          # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ duc_giang_txt/        # Text data
â”‚   â”œâ”€â”€ cache/                     # Cache files
â”‚   â”‚   â””â”€â”€ chatbot_cache.pkl
â”‚   â””â”€â”€ models/                    # LLM models
â”‚       â”œâ”€â”€ qwen2.5-1.5b-instruct-q4_k_m.gguf
â”‚       â””â”€â”€ llama-3.2-1b-instruct-q4_k_m.gguf
â”‚
â”œâ”€â”€ web/                           # Web application
â”‚   â”œâ”€â”€ app.py                     # Flask server
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ style.css
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ run_cli.py                # CLI runner
â”‚   â”œâ”€â”€ download_model.py         # Model downloader
â”‚   â””â”€â”€ setup.py
â”‚
â”œâ”€â”€ tests/                         # Unit tests (tÆ°Æ¡ng lai)
â”œâ”€â”€ logs/                          # Log files
â””â”€â”€ **/__pycache__/                # Python cache (auto-generated)
```

## ğŸ”Œ API Documentation

### POST /api/chat
**Gá»­i cÃ¢u há»i vÃ  nháº­n cÃ¢u tráº£ lá»i**

Request:
```json
{
  "message": "Bá»‡nh viá»‡n cÃ³ khoa nÃ o?",
  "top_k": 5
}
```

Response:
```json
{
  "response": "Dá»±a trÃªn thÃ´ng tin...",
  "time": 2.34,
  "inference_time": 1.23,
  "scores": [
    {
      "rank": 1,
      "similarity": 0.95,
      "probability": 0.87,
      "text": "..."
    }
  ]
}
```

### GET /api/stats
**Láº¥y thá»‘ng kÃª chatbot**

Response:
```json
{
  "total_chunks": 2500,
  "embedding_dim": 384,
  "model": "sentence-transformers/all-MiniLM-L6-v2",
  "llm_enabled": true,
  "llm_model": "data/models/qwen2.5-1.5b-instruct-q4_k_m.gguf"
}
```

### GET /api/health
**Health check**

Response:
```json
{
  "status": "ok",
  "message": "Chatbot is running"
}
```

## ğŸ”§ Cáº¥u hÃ¬nh (config/settings.py)

### CHATBOT_CONFIG
```python
{
    "data_folder": "data/raw/duc_giang_txt",
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
    "chunk_size": 3,
    "top_k": 5,
    "similarity_threshold": 0.3,
    "cache_file": "data/cache/chatbot_cache.pkl",
    "use_llm": True,
    "llm_model_path": "data/models/qwen2.5-1.5b-instruct-q4_k_m.gguf"
}
```

### LLM_CONFIG
```python
{
    "n_ctx": 512,           # Context window
    "n_threads": 4,         # Sá»‘ threads
    "n_batch": 64,          # Batch size
    "temperature": 0.3,     # Äá»™ sÃ¡ng táº¡o
    "top_p": 0.9,          # Sampling
    "max_tokens": 200       # Token tá»‘i Ä‘a
}
```

## ğŸ› ï¸ Troubleshooting

### 1. Lá»—i: "llama-cpp-python chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t"
```bash
pip install llama-cpp-python
```

### 2. Lá»—i: "KhÃ´ng tÃ¬m tháº¥y model LLM"
- Download models tá»« HuggingFace
- Äáº·t vÃ o `data/models/`
- Cáº­p nháº­t Ä‘Æ°á»ng dáº«n trong `config/settings.py`

### 3. Lá»—i: "KhÃ´ng cÃ³ file txt"
- Äáº·t dá»¯ liá»‡u vÃ o `data/raw/duc_giang_txt/`
- Hoáº·c cháº¡y `python scripts/crawler.py`

### 4. XÃ³a cache cÅ©
```bash
rm data/cache/chatbot_cache.pkl
# Láº§n tiáº¿p theo sáº½ rebuild index tá»± Ä‘á»™ng
```

---

**Last Updated**: February 2026
