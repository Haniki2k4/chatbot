# -*- coding: utf-8 -*-
"""
Script t·ª± ƒë·ªông t·∫£i model LLM cho chatbot
T·∫£i model GGUF nh·ªè g·ªçn t·ª´ HuggingFace
"""

import os
import sys
import urllib.request
from pathlib import Path


def download_file(url, output_path):
    """T·∫£i file v·ªõi progress bar"""
    def show_progress(block_num, block_size, total_size):
        downloaded = block_num * block_size
        percent = min(downloaded * 100 / total_size, 100)
        bar_length = 50
        filled_length = int(bar_length * percent / 100)
        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)
        
        sys.stdout.write(f'\r|{bar}| {percent:.1f}% ({downloaded/1024/1024:.1f}MB / {total_size/1024/1024:.1f}MB)')
        sys.stdout.flush()
    
    print(f"üì• ƒêang t·∫£i: {url}")
    urllib.request.urlretrieve(url, output_path, show_progress)
    print("\n‚úÖ T·∫£i xong!")


def main():
    """T·∫£i model LLM"""
    print("="*60)
    print("ü§ñ DOWNLOAD MODEL LLM CHO CHATBOT")
    print("="*60)
    
    # T·∫°o th∆∞ m·ª•c models
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    # Ch·ªçn model (nh·ªè v√† nhanh)
    print("\nüìã C√°c model c√≥ s·∫µn:")
    print("1. Qwen2.5-0.5B-Instruct-Q2_K (~200MB) - Nh·∫π nh·∫•t, ph√π h·ª£p CPU y·∫øu")
    print("2. Llama-3.2-1B-Instruct-Q4_K_M (~550MB) - C√¢n b·∫±ng, khuy·∫øn ngh·ªã")
    print("3. Qwen2.5-1.5B-Instruct-Q4_K_M (~900MB) - T·ªët h∆°n nh∆∞ng n·∫∑ng h∆°n")
    
    choice = input("\nCh·ªçn model (1-3) [m·∫∑c ƒë·ªãnh: 2]: ").strip() or "2"
    
    models = {
        "1": {
            "name": "qwen2.5-0.5b-instruct-q2_k.gguf",
            "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q2_k.gguf",
            "size": "~200MB"
        },
        "2": {
            "name": "llama-3.2-1b-instruct-q4_k_m.gguf",
            "url": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
            "size": "~550MB"
        },
        "3": {
            "name": "qwen2.5-1.5b-instruct-q4_k_m.gguf",
            "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf",
            "size": "~900MB"
        }
    }
    
    if choice not in models:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
        return
    
    model = models[choice]
    output_path = models_dir / model["name"]
    
    # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i
    if output_path.exists():
        print(f"\n‚ö†Ô∏è  File {model['name']} ƒë√£ t·ªìn t·∫°i")
        overwrite = input("T·∫£i l·∫°i? (y/n) [n]: ").strip().lower()
        if overwrite != 'y':
            print("‚úÖ S·ª≠ d·ª•ng file c√≥ s·∫µn")
            return
    
    # T·∫£i model
    print(f"\nüîΩ Model: {model['name']}")
    print(f"üì¶ K√≠ch th∆∞·ªõc: {model['size']}")
    print(f"üíæ ƒê∆∞·ªùng d·∫´n: {output_path.absolute()}")
    print("\n‚è≥ B·∫Øt ƒë·∫ßu t·∫£i... (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)")
    
    try:
        download_file(model["url"], str(output_path))
        print(f"\n‚úÖ Ho√†n t·∫•t! Model ƒë√£ l∆∞u t·∫°i: {output_path.absolute()}")
        print("\nüí° Ti·∫øp theo:")
        print("   1. Ch·∫°y chatbot: python app.py")
        print("   2. Model s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c load n·∫øu ·ªü ƒë√∫ng v·ªã tr√≠")
    except Exception as e:
        print(f"\n‚ùå L·ªói khi t·∫£i model: {e}")
        print("\nüí° N·∫øu l·ªói, b·∫°n c√≥ th·ªÉ:")
        print(f"   1. T·∫£i th·ªß c√¥ng t·ª´: {model['url']}")
        print(f"   2. L∆∞u v√†o: {output_path.absolute()}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  ƒê√£ h·ªßy t·∫£i xu·ªëng")
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
